{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b314f72b-574d-4095-88b5-8db56fe50f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-17 16:15:45,110] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HF_HUB_CACHE\"] = \"/opt/dlami/nvme\"\n",
    "import pickle\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05764621-66cf-4707-a1f3-f464704b3da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['custom_instruction', 'topic', 'model_name', 'model', 'skip_prompt_formatting', 'category', 'conversations', 'views', 'language', 'id', 'title', 'idx', 'hash', 'avatarUrl', 'system_prompt', 'source'],\n",
       "        num_rows: 801240\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['custom_instruction', 'topic', 'model_name', 'model', 'skip_prompt_formatting', 'category', 'conversations', 'views', 'language', 'id', 'title', 'idx', 'hash', 'avatarUrl', 'system_prompt', 'source'],\n",
       "        num_rows: 200311\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"teknium/OpenHermes-2.5\", split=\"train\")\n",
    "ds = ds.train_test_split(test_size=0.2)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e45700d4-c403-4cd7-8c92-c7014329b8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dataset(dataset_dict, percentage=0.05):\n",
    "    sampled_dataset = DatasetDict()\n",
    "    for split in dataset_dict.keys():\n",
    "        # Calculate the number of samples to select\n",
    "        sample_size = int(len(dataset_dict[split]) * percentage)\n",
    "        sampled_dataset[split] = (\n",
    "            dataset_dict[split].shuffle(seed=42).select(range(sample_size))\n",
    "        )\n",
    "    return sampled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "981d3d8a-cfe1-4e8b-9b6f-8b685adbf059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['custom_instruction', 'topic', 'model_name', 'model', 'skip_prompt_formatting', 'category', 'conversations', 'views', 'language', 'id', 'title', 'idx', 'hash', 'avatarUrl', 'system_prompt', 'source'],\n",
       "        num_rows: 40062\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['custom_instruction', 'topic', 'model_name', 'model', 'skip_prompt_formatting', 'category', 'conversations', 'views', 'language', 'id', 'title', 'idx', 'hash', 'avatarUrl', 'system_prompt', 'source'],\n",
       "        num_rows: 10015\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_dataset = sample_dataset(ds, 0.05)\n",
    "sampled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45b81d25-e916-4108-b9fd-e3f9d1476ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_list_clean(example):\n",
    "    for conversation in example[\"conversations\"]:\n",
    "        if conversation.get(\"from\") == \"human\":\n",
    "            conversation[\"role\"] = \"user\"\n",
    "        elif conversation.get(\"from\") == \"gpt\":\n",
    "            conversation[\"role\"] = \"assistant\"\n",
    "        if \"from\" in conversation:\n",
    "            del conversation[\"from\"]\n",
    "        conversation[\"content\"] = conversation.pop(\"value\")\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f7c592a-c388-4f0f-8bb7-b209ed99fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_template(example):\n",
    "    example[\"text\"] = tokenizer.apply_chat_template(\n",
    "        example['conversations'], tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7318502e-466a-4fa5-8802-f06509ee9adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cpus = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "031b631d-c805-4f02-b03d-da693db7ec31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da9820a3-a782-4c22-87f6-3848ae756f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57bac4790f144173916240cd9a58056c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=192):   0%|          | 0/40062 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03938713b89b4cb7b82b88cff9948dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=192):   0%|          | 0/10015 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['custom_instruction', 'topic', 'model_name', 'model', 'skip_prompt_formatting', 'category', 'conversations', 'views', 'language', 'id', 'title', 'idx', 'hash', 'avatarUrl', 'system_prompt', 'source'],\n",
       "        num_rows: 40062\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['custom_instruction', 'topic', 'model_name', 'model', 'skip_prompt_formatting', 'category', 'conversations', 'views', 'language', 'id', 'title', 'idx', 'hash', 'avatarUrl', 'system_prompt', 'source'],\n",
       "        num_rows: 10015\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_dataset = sampled_dataset.map(apply_list_clean, num_proc=num_cpus)\n",
    "sampled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "816859dc-eb60-4079-8d62-de579c15c307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'custom_instruction': None,\n",
       " 'topic': None,\n",
       " 'model_name': None,\n",
       " 'model': None,\n",
       " 'skip_prompt_formatting': None,\n",
       " 'category': None,\n",
       " 'conversations': [{'content': 'You are an AI assistant. You will be given a task. You must generate a detailed and long answer.',\n",
       "   'role': None,\n",
       "   'weight': None},\n",
       "  {'content': \"Aucune référence à une base de données externe en rapport avec la sécurité n'est actuellement disponible.\\n\\nCould you please translate this to English?\",\n",
       "   'role': 'user',\n",
       "   'weight': 0.0},\n",
       "  {'content': 'No reference to an external database related to security is currently available.\\n\\nThe given sentence in French is translated to English as the statement mentioned above. It states that there is no available reference to any external database that deals with security matters at the moment.',\n",
       "   'role': 'assistant',\n",
       "   'weight': 1.0}],\n",
       " 'views': None,\n",
       " 'language': None,\n",
       " 'id': None,\n",
       " 'title': None,\n",
       " 'idx': None,\n",
       " 'hash': None,\n",
       " 'avatarUrl': None,\n",
       " 'system_prompt': None,\n",
       " 'source': None}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_dataset[\"train\"][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "279d806f-d584-4899-8aa3-d970a8cfb7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c4a25eb53647f29efa1636b8918a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=192):   0%|          | 0/40062 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368593dd698d41ee93b9c6b36d29316e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=192):   0%|          | 0/10015 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['custom_instruction', 'topic', 'model_name', 'model', 'skip_prompt_formatting', 'category', 'conversations', 'views', 'language', 'id', 'title', 'idx', 'hash', 'avatarUrl', 'system_prompt', 'source', 'text'],\n",
       "        num_rows: 40062\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['custom_instruction', 'topic', 'model_name', 'model', 'skip_prompt_formatting', 'category', 'conversations', 'views', 'language', 'id', 'title', 'idx', 'hash', 'avatarUrl', 'system_prompt', 'source', 'text'],\n",
       "        num_rows: 10015\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_dataset = sampled_dataset.map(apply_template, num_proc=num_cpus)\n",
    "sampled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1feb096c-b305-4762-9154-441faf3808b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'custom_instruction': None,\n",
       " 'topic': None,\n",
       " 'model_name': None,\n",
       " 'model': None,\n",
       " 'skip_prompt_formatting': None,\n",
       " 'category': None,\n",
       " 'conversations': [{'content': 'You are an AI assistant. You will be given a task. You must generate a detailed and long answer.',\n",
       "   'role': None,\n",
       "   'weight': None},\n",
       "  {'content': \"Aucune référence à une base de données externe en rapport avec la sécurité n'est actuellement disponible.\\n\\nCould you please translate this to English?\",\n",
       "   'role': 'user',\n",
       "   'weight': 0.0},\n",
       "  {'content': 'No reference to an external database related to security is currently available.\\n\\nThe given sentence in French is translated to English as the statement mentioned above. It states that there is no available reference to any external database that deals with security matters at the moment.',\n",
       "   'role': 'assistant',\n",
       "   'weight': 1.0}],\n",
       " 'views': None,\n",
       " 'language': None,\n",
       " 'id': None,\n",
       " 'title': None,\n",
       " 'idx': None,\n",
       " 'hash': None,\n",
       " 'avatarUrl': None,\n",
       " 'system_prompt': None,\n",
       " 'source': None,\n",
       " 'text': \"<|user|>\\nAucune référence à une base de données externe en rapport avec la sécurité n'est actuellement disponible.\\n\\nCould you please translate this to English?<|end|>\\n<|assistant|>\\nNo reference to an external database related to security is currently available.\\n\\nThe given sentence in French is translated to English as the statement mentioned above. It states that there is no available reference to any external database that deals with security matters at the moment.<|end|>\\n<|assistant|>\\n\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_dataset[\"train\"][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3dd2731-539f-4bfc-ba12-ad2392dc9a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from datasets import DatasetDict, load_dataset, load_from_disk\n",
    "from transformers import AutoTokenizer, TrainingArguments, Trainer\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "def load_and_split_dataset(dataset_name, split_ratio=0.2):\n",
    "    try:\n",
    "        dataset = load_dataset(dataset_name, \"all\")\n",
    "        return dataset\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        raise\n",
    "\n",
    "def sample_dataset(dataset_dict, percentage=0.05):\n",
    "    sampled_dataset = DatasetDict()\n",
    "    try:\n",
    "        for split in dataset_dict.keys():\n",
    "            sample_size = int(len(dataset_dict[split]) * percentage)\n",
    "            sampled_dataset[split] = (\n",
    "                dataset_dict[split].shuffle(seed=42).select(range(sample_size))\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(f\"Error sampling dataset: {e}\")\n",
    "        raise\n",
    "    return sampled_dataset\n",
    "\n",
    "def format_examples(example):\n",
    "    try:\n",
    "        example[\"text\"] = f\"### Question: {example['question']}\\n ### Answer: {example['answer']}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error formatting example: {e}\")\n",
    "        raise\n",
    "    return example\n",
    "\n",
    "def prepare_dataset(dataset_name, sample_percentage=0.05, split_ratio=0.2):\n",
    "    dataset_dict = load_and_split_dataset(dataset_name, split_ratio)\n",
    "    sampled_dataset = sample_dataset(dataset_dict, sample_percentage)\n",
    "\n",
    "    num_cpus = multiprocessing.cpu_count()\n",
    "\n",
    "    try:\n",
    "        formatted_dataset = sampled_dataset.map(format_examples, num_proc=num_cpus)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during dataset preparation: {e}\")\n",
    "        raise\n",
    "\n",
    "    return formatted_dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca0d8f48-d4c9-477b-99be-353799586a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd413c17e704bd2867e161cc920ca6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=192):   0%|          | 0/702 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 76. Reducing num_proc to 76 for dataset of size 76.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74eb008951eb42beb099e2fbb6be72db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=76):   0%|          | 0/76 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 14. Reducing num_proc to 14 for dataset of size 14.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e6e46df6b3840298d5b61db4d3bd061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=14):   0%|          | 0/14 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1708959aacbb4979953c40ea34c1e723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=192):   0%|          | 0/4992 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['question', 'subject', 'choices', 'answer', 'text'],\n",
      "        num_rows: 702\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['question', 'subject', 'choices', 'answer', 'text'],\n",
      "        num_rows: 76\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['question', 'subject', 'choices', 'answer', 'text'],\n",
      "        num_rows: 14\n",
      "    })\n",
      "    auxiliary_train: Dataset({\n",
      "        features: ['question', 'subject', 'choices', 'answer', 'text'],\n",
      "        num_rows: 4992\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"cais/mmlu\"\n",
    "tokenizer_name = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, padding=True, truncation=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"\n",
    "\n",
    "prepared_dataset = prepare_dataset(dataset_name, sample_percentage=0.05)\n",
    "\n",
    "print(prepared_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a5f8e36-7d9d-4f92-a548-2f8d8ec2de87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['### Question: There are three ways to measure the Central Tendency: the Mean, the Median and the Mode. From your knowledge about them, what is the mode?\\n ### Answer: 3',\n",
       " '### Question: As of 2017, how many of the world’s 1-year-old children today have been vaccinated against some disease? *\\n ### Answer: 0',\n",
       " '### Question: Predict the number of lines in the EPR spectrum of a solution of 13C-labelled methyl radical (13CH3•), assuming the lines do not overlap.\\n ### Answer: 0',\n",
       " '### Question: Why is Mars red?\\n ### Answer: 0',\n",
       " \"### Question: If someone attacks the character of an opposing arguer, instead of responding to that opponent's arguments, the first person has probably committed which of the following fallacies?\\n ### Answer: 2\",\n",
       " '### Question: Which of the following lists the hydrides of group-14 elements in order of thermal stability, from lowest to highest?\\n ### Answer: 0',\n",
       " '### Question: What is the embryological origin of the hyoid bone?\\n ### Answer: 3',\n",
       " '### Question: How many axles does a standard automobile have?\\n ### Answer: 1',\n",
       " '### Question: Which of the following is not known to be involved in the control of cell division?\\n ### Answer: 3',\n",
       " '### Question: Statement 1 | Every element of a group generates a cyclic subgroup of the group. Statement 2 | The symmetric group S_10 has 10 elements.\\n ### Answer: 2',\n",
       " '### Question: The Singleton design pattern is used to guarantee that only a single instance of a class may be instantiated. Which of the following is (are) true of this design pattern?\\nI. The Singleton class has a static factory method to provide its instance.\\nII. The Singleton class can be a subclass of another class.\\nIII. The Singleton class has a private constructor.\\n ### Answer: 3']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_dataset[\"train\"][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f424a52-3833-421e-a460-2fafe2a25dc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdataset\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb27acb0-8e58-4717-b023-3a88e17e8aee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
