{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b314f72b-574d-4095-88b5-8db56fe50f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-12 11:38:43,235] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_CACHE\"] = \"/opt/dlami/nvme\"\n",
    "import pickle\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05764621-66cf-4707-a1f3-f464704b3da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['custom_instruction', 'topic', 'model_name', 'model', 'skip_prompt_formatting', 'category', 'conversations', 'views', 'language', 'id', 'title', 'idx', 'hash', 'avatarUrl', 'system_prompt', 'source'],\n",
       "        num_rows: 801240\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['custom_instruction', 'topic', 'model_name', 'model', 'skip_prompt_formatting', 'category', 'conversations', 'views', 'language', 'id', 'title', 'idx', 'hash', 'avatarUrl', 'system_prompt', 'source'],\n",
       "        num_rows: 200311\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"teknium/OpenHermes-2.5\", split=\"train\")\n",
    "ds = ds.train_test_split(test_size=0.2)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e45700d4-c403-4cd7-8c92-c7014329b8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dataset(dataset_dict, percentage=0.05):\n",
    "    sampled_dataset = DatasetDict()\n",
    "    for split in dataset_dict.keys():\n",
    "        # Calculate the number of samples to select\n",
    "        sample_size = int(len(dataset_dict[split]) * percentage)\n",
    "        sampled_dataset[split] = dataset_dict[split].shuffle(seed=42).select(range(sample_size))\n",
    "    return sampled_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "981d3d8a-cfe1-4e8b-9b6f-8b685adbf059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['custom_instruction', 'topic', 'model_name', 'model', 'skip_prompt_formatting', 'category', 'conversations', 'views', 'language', 'id', 'title', 'idx', 'hash', 'avatarUrl', 'system_prompt', 'source'],\n",
       "        num_rows: 40062\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['custom_instruction', 'topic', 'model_name', 'model', 'skip_prompt_formatting', 'category', 'conversations', 'views', 'language', 'id', 'title', 'idx', 'hash', 'avatarUrl', 'system_prompt', 'source'],\n",
       "        num_rows: 10015\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_dataset = sample_dataset(ds, 0.05)\n",
    "sampled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45b81d25-e916-4108-b9fd-e3f9d1476ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_list_clean(example):\n",
    "    for conversation in example[\"conversations\"]:\n",
    "        if conversation.get(\"from\") == \"human\":\n",
    "            conversation[\"role\"] = \"user\"\n",
    "        elif conversation.get(\"from\") == \"gpt\":\n",
    "            conversation[\"role\"] = \"assistant\"\n",
    "        if \"from\" in conversation:\n",
    "            del conversation[\"from\"]\n",
    "        conversation[\"content\"] = conversation.pop(\"value\")\n",
    "    return example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f7c592a-c388-4f0f-8bb7-b209ed99fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_template(example):\n",
    "    example[\"text\"] = tokenizer.apply_chat_template(example['conversations'], tokenize=False, add_generation_prompt=True)\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7318502e-466a-4fa5-8802-f06509ee9adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cpus = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "031b631d-c805-4f02-b03d-da693db7ec31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da9820a3-a782-4c22-87f6-3848ae756f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57bac4790f144173916240cd9a58056c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=192):   0%|          | 0/40062 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03938713b89b4cb7b82b88cff9948dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=192):   0%|          | 0/10015 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['custom_instruction', 'topic', 'model_name', 'model', 'skip_prompt_formatting', 'category', 'conversations', 'views', 'language', 'id', 'title', 'idx', 'hash', 'avatarUrl', 'system_prompt', 'source'],\n",
       "        num_rows: 40062\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['custom_instruction', 'topic', 'model_name', 'model', 'skip_prompt_formatting', 'category', 'conversations', 'views', 'language', 'id', 'title', 'idx', 'hash', 'avatarUrl', 'system_prompt', 'source'],\n",
       "        num_rows: 10015\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_dataset = sampled_dataset.map(apply_list_clean, num_proc=num_cpus)\n",
    "sampled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "816859dc-eb60-4079-8d62-de579c15c307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'custom_instruction': None,\n",
       " 'topic': None,\n",
       " 'model_name': None,\n",
       " 'model': None,\n",
       " 'skip_prompt_formatting': None,\n",
       " 'category': None,\n",
       " 'conversations': [{'content': 'You are an AI assistant. You will be given a task. You must generate a detailed and long answer.',\n",
       "   'role': None,\n",
       "   'weight': None},\n",
       "  {'content': \"Aucune référence à une base de données externe en rapport avec la sécurité n'est actuellement disponible.\\n\\nCould you please translate this to English?\",\n",
       "   'role': 'user',\n",
       "   'weight': 0.0},\n",
       "  {'content': 'No reference to an external database related to security is currently available.\\n\\nThe given sentence in French is translated to English as the statement mentioned above. It states that there is no available reference to any external database that deals with security matters at the moment.',\n",
       "   'role': 'assistant',\n",
       "   'weight': 1.0}],\n",
       " 'views': None,\n",
       " 'language': None,\n",
       " 'id': None,\n",
       " 'title': None,\n",
       " 'idx': None,\n",
       " 'hash': None,\n",
       " 'avatarUrl': None,\n",
       " 'system_prompt': None,\n",
       " 'source': None}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_dataset[\"train\"][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "279d806f-d584-4899-8aa3-d970a8cfb7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c4a25eb53647f29efa1636b8918a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=192):   0%|          | 0/40062 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368593dd698d41ee93b9c6b36d29316e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=192):   0%|          | 0/10015 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['custom_instruction', 'topic', 'model_name', 'model', 'skip_prompt_formatting', 'category', 'conversations', 'views', 'language', 'id', 'title', 'idx', 'hash', 'avatarUrl', 'system_prompt', 'source', 'text'],\n",
       "        num_rows: 40062\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['custom_instruction', 'topic', 'model_name', 'model', 'skip_prompt_formatting', 'category', 'conversations', 'views', 'language', 'id', 'title', 'idx', 'hash', 'avatarUrl', 'system_prompt', 'source', 'text'],\n",
       "        num_rows: 10015\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_dataset = sampled_dataset.map(apply_template, num_proc=num_cpus)\n",
    "sampled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1feb096c-b305-4762-9154-441faf3808b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'custom_instruction': None,\n",
       " 'topic': None,\n",
       " 'model_name': None,\n",
       " 'model': None,\n",
       " 'skip_prompt_formatting': None,\n",
       " 'category': None,\n",
       " 'conversations': [{'content': 'You are an AI assistant. You will be given a task. You must generate a detailed and long answer.',\n",
       "   'role': None,\n",
       "   'weight': None},\n",
       "  {'content': \"Aucune référence à une base de données externe en rapport avec la sécurité n'est actuellement disponible.\\n\\nCould you please translate this to English?\",\n",
       "   'role': 'user',\n",
       "   'weight': 0.0},\n",
       "  {'content': 'No reference to an external database related to security is currently available.\\n\\nThe given sentence in French is translated to English as the statement mentioned above. It states that there is no available reference to any external database that deals with security matters at the moment.',\n",
       "   'role': 'assistant',\n",
       "   'weight': 1.0}],\n",
       " 'views': None,\n",
       " 'language': None,\n",
       " 'id': None,\n",
       " 'title': None,\n",
       " 'idx': None,\n",
       " 'hash': None,\n",
       " 'avatarUrl': None,\n",
       " 'system_prompt': None,\n",
       " 'source': None,\n",
       " 'text': \"<|user|>\\nAucune référence à une base de données externe en rapport avec la sécurité n'est actuellement disponible.\\n\\nCould you please translate this to English?<|end|>\\n<|assistant|>\\nNo reference to an external database related to security is currently available.\\n\\nThe given sentence in French is translated to English as the statement mentioned above. It states that there is no available reference to any external database that deals with security matters at the moment.<|end|>\\n<|assistant|>\\n\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_dataset[\"train\"][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dd2731-539f-4bfc-ba12-ad2392dc9a67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
